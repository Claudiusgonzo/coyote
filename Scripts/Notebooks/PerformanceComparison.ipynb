{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import statistics\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "import bokeh.io\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.models.ranges import FactorRange\n",
    "from bokeh.transform import factor_cmap\n",
    "from bokeh.resources import INLINE\n",
    "import bokeh.io\n",
    "\n",
    "bokeh.io.reset_output()\n",
    "bokeh.io.output_notebook(INLINE)\n",
    "\n",
    "#bokeh.io.output_notebook()\n",
    "\n",
    "def methods(obj):\n",
    "    print('Methods:')\n",
    "    print('\\n'.join([x for x in dir(obj) if not x.startswith('_')]))\n",
    "\n",
    "# this log contains: git log --pretty=medium > d:\\temp\\performance\\commits.log\n",
    "commitlog = \"d:/temp/performance/commits.log\"\n",
    "\n",
    "width = 800\n",
    "height = 332\n",
    "\n",
    "class Report(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d\n",
    "        \n",
    "class Result():\n",
    "    def __init__(self):\n",
    "        self.Name = \"\"\n",
    "        self.HasHalt = False\n",
    "        self.DoHalt = False\n",
    "        self.Iterations = 0\n",
    "        self.Mean = 0\n",
    "        self.Error = 0\n",
    "        self.StdDev = 0\n",
    "        self.Min = 0\n",
    "        self.Max = 0\n",
    "        self.CPU = 0\n",
    "        self.Collected = 0\n",
    "        \n",
    "class Benchmark():\n",
    "    def __init__(self, filename, data):\n",
    "        self.filename = filename\n",
    "        self.data = data\n",
    "        self.name = data[0].Name       \n",
    "\n",
    "class DataPoint:\n",
    "    def __init__(self, index, mean, min_value, max_value, error, cpu, collected, name):\n",
    "        self.index = index\n",
    "        self.mean = mean\n",
    "        self.ci0 = min_value\n",
    "        self.ci1 = max_value\n",
    "        self.error = error\n",
    "        self.name = name\n",
    "        self.cpu = cpu\n",
    "        self.collected = collected\n",
    "        \n",
    "def print_stats(name, values):\n",
    "    min_value = min(values)\n",
    "    max_value = max(values)\n",
    "    spread = max_value - min_value\n",
    "    print(\"{} has min={}, max={:.3f}, error={:.3f}%\".format(name, min_value, max_value, spread * 100 / statistics.mean(values)))\n",
    "              \n",
    "def to_millis(v):\n",
    "    p = v.split(' ')    \n",
    "    t = float(p[0].replace(\",\",\"\"))\n",
    "    if len(p) == 1:\n",
    "        return t\n",
    "    units = p[1]\n",
    "    if units == \"ms\":\n",
    "        return t\n",
    "    if units == \"s\":\n",
    "        return t * 1000\n",
    "    if units == \"Î¼s\":\n",
    "        return float(t) / 1000.0\n",
    "    raise Exception(\"Unknown units {}\".format(v))\n",
    "\n",
    "def get_pallete(count):\n",
    "    # see https://docs.bokeh.org/en/latest/docs/reference/palettes.html\n",
    "    if count < 10:\n",
    "        return bokeh.palettes.d3['Category10'][max(3, count)]\n",
    "    else:\n",
    "        return bokeh.palettes.d3['Category20'][max(3, count)]\n",
    "    \n",
    "def load_commits(filename):\n",
    "    result = []\n",
    "    commit = None\n",
    "    author = None\n",
    "    date = None\n",
    "    with open(filename, \"r\", errors='ignore') as f:\n",
    "        for line in f.readlines():\n",
    "            if line.startswith(\"commit \"):\n",
    "                commit = line[7:].strip()\n",
    "            elif line.startswith(\"Author: \"):\n",
    "                author = line[8:].strip()\n",
    "            elif line.startswith(\"Date: \"):\n",
    "                date = line[6:].strip()\n",
    "                date = datetime.datetime.strptime(date, '%a %b %d %H:%M:%S %Y %z')\n",
    "                result += [(commit,author,date)]\n",
    "    return result\n",
    "\n",
    "def strip_dict(d):\n",
    "    h = {}\n",
    "    for k in d:\n",
    "        ks = k.replace(\" \",\"\").replace(\"\\ufeff\",\"\")\n",
    "        h[ks] = d[k].strip()\n",
    "    return h\n",
    "        \n",
    "def load_report(filename):\n",
    "    result = []\n",
    "    with open(filename, \"r\", encoding='utf8') as f:\n",
    "        dr = csv.DictReader(f);\n",
    "        for row in dr:\n",
    "            try:\n",
    "                row = strip_dict(row)\n",
    "                r = Report(row)\n",
    "                x = Result()\n",
    "                iterations = 0\n",
    "\n",
    "                if \"Method\" in row:\n",
    "                    x.Name = r.Method\n",
    "                elif \"Name\" in row:\n",
    "                    parts = r.Name.split(' ')\n",
    "                    x.Name = parts[0]\n",
    "                    for p in parts[1:]:\n",
    "                        nv = p.split('=')\n",
    "                        if len(nv) == 2:\n",
    "                            if nv[0] == \"DoHalt\":\n",
    "                                x.HasHalt = True;\n",
    "                                x.DoHalt = bool(nv[1])\n",
    "                            elif nv[0] in [\"NumMachines\", \"NumProducers\", \"NumMessages\", \"NumTransitions\", \"NumConsumers\"]:\n",
    "                                iterations = int(nv[1])\n",
    "                            else:\n",
    "                                raise Exception(\"Error parsing keyvalue {}\".format(p))\n",
    "                    \n",
    "                if \"NumProducers\" in row:\n",
    "                    iterations = int(r.NumProducers)\n",
    "                elif \"NumMachines\" in row:\n",
    "                    iterations = int(r.NumMachines)\n",
    "                elif \"NumMessages\" in row:\n",
    "                    iterations = int(r.NumMessages)\n",
    "                elif \"NumTransitions\" in row:\n",
    "                    iterations = int(r.NumTransitions)\n",
    "                elif \"NumConsumers\" in row:\n",
    "                    iterations = int(r.NumConsumers)\n",
    "                    \n",
    "                if \"DoHalt\" in row:\n",
    "                    x.DoHalt = r.DoHalt == \"True\"\n",
    "                    x.HasHalt = True\n",
    "                if \"CPU%\" in row:                    \n",
    "                    x.CPU = float(row[\"CPU%\"])\n",
    "                elif \"Cpu\" in row:\n",
    "                    x.CPU = float(row[\"Cpu\"])\n",
    "                if \"Gen 0\" in row:                    \n",
    "                    x.Collected += float(row[\"Gen 0\"])\n",
    "                    x.Collected += float(row[\"Gen 1\"])\n",
    "                    x.Collected += float(row[\"Gen 2\"])\n",
    "                    \n",
    "                # .NET Core runs are failing for some reason.\n",
    "                if \"MinTime\" in row:\n",
    "                    x.Min = float(r.MinTime)\n",
    "                    x.StdDev = float(r.StdDevTime)\n",
    "                    x.Mean = x.Min;\n",
    "                    x.Max = x.Min + x.StdDev\n",
    "                    x.Iterations = iterations\n",
    "                    result += [x];\n",
    "                    \n",
    "                elif r.Runtime == \"Clr\" or r.Runtime == \".NET 4.8\" or r.Runtime == \".NET Core 3.1\":\n",
    "                    x.Mean = to_millis(r.Mean)\n",
    "                    x.Error = to_millis(r.Error)\n",
    "                    x.StdDev = to_millis(r.StdDev)\n",
    "                    if \"Min\" in row:\n",
    "                        x.Min =  to_millis(r.Min)\n",
    "                    else:\n",
    "                        x.Min = x.Mean - x.Error\n",
    "                    if \"Max\" in row:\n",
    "                        x.Max = to_millis(r.Max)\n",
    "                    else:\n",
    "                        x.Max = x.Mean + x.Error\n",
    "                    x.Iterations = iterations\n",
    "                    result += [x];\n",
    "            except Exception as e:\n",
    "                print(\"Error loading row: \" + \",\".join(row.keys()))\n",
    "                print(e)\n",
    "                \n",
    "    return Benchmark(filename, result)\n",
    "\n",
    "def load_graphs(rootdir):\n",
    "    benchmarks = []\n",
    "    for name in os.listdir(rootdir):\n",
    "        if name.startswith(\"benchmark_\") and not name.endswith(\".zip\"):\n",
    "            benchmarks += [name]\n",
    "\n",
    "    loaded = {}\n",
    "    for name in benchmarks:\n",
    "        b = os.path.join(rootdir, name)\n",
    "        results = os.path.join(b, \"results\")\n",
    "        pattern = \".csv\"\n",
    "        if os.path.exists(results):\n",
    "            b = results\n",
    "            pattern = \"report.csv\"\n",
    "        for report in os.listdir(b):\n",
    "            if report.endswith(pattern) and not report.endswith(\"summary.csv\"):\n",
    "                r = load_report(os.path.join(b, report))\n",
    "                r.commit = name[10:]\n",
    "                if r.name in loaded:\n",
    "                    rows = loaded[r.name]\n",
    "                    rows += [r]\n",
    "                else:\n",
    "                    loaded[r.name] = [r]\n",
    "\n",
    "    commits = load_commits(commitlog)\n",
    "    commits.reverse()\n",
    "\n",
    "    graphs = []\n",
    "\n",
    "    for name in loaded.keys():    \n",
    "        benchmark = loaded[name]\n",
    "        iterations = list(set([i.Iterations for i in benchmark[0].data]))\n",
    "        iterations.sort()\n",
    "        tests = list(set(i.Name for i in benchmark[0].data))\n",
    "        tests.sort()\n",
    "        for t in tests:\n",
    "            for i in iterations:\n",
    "                for b in [True,False]:\n",
    "                    if benchmark[0].data[0].HasHalt:\n",
    "                        title = \"{} {} Halt={}\".format(t, i, b)                    \n",
    "                    else:\n",
    "                        title = \"{} {}\".format(t, i)\n",
    "\n",
    "                    series = []\n",
    "                    index = 0\n",
    "                    skipped = False\n",
    "                    # order the chart by commit order so it shows history.\n",
    "                    for commit, author, date in commits:\n",
    "                        matching_commit = [x for x in benchmark if x.commit == commit]\n",
    "                        if len(matching_commit):\n",
    "                            for x in matching_commit[0].data:\n",
    "                                halt_match = (x.HasHalt and x.DoHalt == b) or (x.HasHalt == False and b == True)\n",
    "                                if index == 17 and not skipped:\n",
    "                                    skipped = True\n",
    "                                elif x.Iterations == i and x.Name == t and halt_match:\n",
    "                                    mean = x.Mean\n",
    "                                    series += [DataPoint(index, mean, x.Min, x.Max, x.Error, x.CPU, x.Collected, commit).__dict__]\n",
    "                                    index += 1\n",
    "                    if len(series):\n",
    "                        graphs += [(title, series)]\n",
    "    return graphs\n",
    "\n",
    "def compare_datasets(datasets):\n",
    "    min_length = sys.maxsize\n",
    "    test_count = sys.maxsize\n",
    "    groups = []\n",
    "    data = {}\n",
    "    palette = get_pallete(len(datasets))\n",
    "    for ds in datasets:\n",
    "        min_length = min(min_length, len(ds))\n",
    "        groups += [str(len(groups) + 1)]            \n",
    "        \n",
    "    for i in range(min_length):\n",
    "        data = []\n",
    "        title = \"\"\n",
    "        for j in range(len(datasets)):\n",
    "            run = datasets[j][i]\n",
    "            if not title:\n",
    "                title = run[0]\n",
    "                print(title)\n",
    "            test_count = min(test_count, len(run[1]))\n",
    "            xlabel = str(j + 1)\n",
    "            measurements = pd.DataFrame(run[1])[\"mean\"][:test_count].values\n",
    "            data += [measurements]\n",
    "            print_stats(\"run{}\".format(j), measurements)\n",
    "            \n",
    "        index = list(range(test_count))\n",
    "        x = [ (str(x), g) for x in index for g in groups ]\n",
    "        \n",
    "        yvalues = sum(zip(*data), ())\n",
    "        source = ColumnDataSource(data=dict(x=x, counts=yvalues))\n",
    "\n",
    "        p = figure(x_range=FactorRange(*x), plot_height=height, plot_width=width, title=title + \", min times\",\n",
    "                   toolbar_location=None, tools=\"\")\n",
    "\n",
    "        p.vbar(x='x', top='counts', width=0.9, source=source, line_color=\"white\",\n",
    "               fill_color=factor_cmap('x', palette=palette, factors=groups, start=1, end=len(groups)))\n",
    "\n",
    "        p.y_range.start = math.floor(min(yvalues) / 10) * 10\n",
    "        p.x_range.range_padding = 0.05\n",
    "        p.yaxis.axis_label = \"milliseconds\"\n",
    "        p.xaxis.major_label_orientation = 1\n",
    "        p.xgrid.grid_line_color = None\n",
    "        p.xaxis.major_label_text_font_size=\"0px\"\n",
    "        p.xaxis.major_tick_line_alpha=0\n",
    "\n",
    "        show(p)\n",
    "        \n",
    "def plots_with_error_bars(datasets):\n",
    "    palette = get_pallete(len(datasets))\n",
    "    chart_count = len(datasets[0])\n",
    "    for i in range(chart_count):\n",
    "        title, _ = datasets[0][i]\n",
    "        print(title)\n",
    "        p = figure(plot_height=height, plot_width=width, title=title)\n",
    "        index = 0\n",
    "        for ds in datasets:\n",
    "            title, data = ds[i]\n",
    "            df = pd.DataFrame(data)[\"mean\"]\n",
    "            xs = [x for x in df.index]\n",
    "            ys = df.values\n",
    "            yerrs = pd.DataFrame(data)[\"error\"].values\n",
    "            print_stats(\"run{}\".format(index), ys)\n",
    "        \n",
    "            # create the coordinates for the errorbars             \n",
    "            err_xs = []\n",
    "            err_ys = []\n",
    "\n",
    "            for x, y, yerr in zip(xs, ys, yerrs):\n",
    "                err_xs.append((x, x))\n",
    "                err_ys.append((y - yerr, y + yerr))\n",
    "\n",
    "            # plot them\n",
    "            color = palette[index]\n",
    "            index += 1\n",
    "            p.multi_line(err_xs, err_ys, color=color)\n",
    "            p.circle(xs, ys, color=color, size=5, line_alpha=0) \n",
    "\n",
    "            if p.y_range.start:\n",
    "                p.y_range.start = min(p.y_range.start, math.floor(min(ys) / 10) * 10)\n",
    "            else:\n",
    "                p.y_range.start = math.floor(min(ys) / 10) * 10\n",
    "        show(p)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Benchmark Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset1 = load_graphs(\"D:\\\\Temp\\\\performance\\\\benchmark_newhistory1\")\n",
    "dataset2 = load_graphs(\"D:\\\\Temp\\\\performance\\\\benchmark_newhistory2\")\n",
    "plots_with_error_bars([dataset1, dataset2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset1 = load_graphs(\"D:\\\\Temp\\\\performance\\\\benchmark_history\")\n",
    "dataset2 = load_graphs(\"D:\\\\Temp\\\\performance\\\\benchmark_history2\")\n",
    "dataset3 = load_graphs(\"D:\\\\Temp\\\\performance\\\\benchmark_history3\")\n",
    "dataset4 = load_graphs(\"D:\\\\Temp\\\\performance\\\\benchmark_history4\")\n",
    "dataset5 = load_graphs(\"D:\\\\Temp\\\\performance\\\\benchmark_history5\")\n",
    "plots_with_error_bars([dataset1, dataset2, dataset3, dataset4, dataset5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimums from each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_minimal_dataset(datasets):\n",
    "    chart_count = len(datasets[0])\n",
    "    minimal_dataset = []\n",
    "    for i in range(chart_count):\n",
    "        minimal_data = None\n",
    "        title = \"\"\n",
    "        for ds in datasets:\n",
    "            title, data = ds[i]\n",
    "            if not minimal_data:\n",
    "                minimal_data = data\n",
    "            else:\n",
    "                for j in range(min(len(data), len(minimal_data))):\n",
    "                    if minimal_data[j][\"mean\"] > data[j][\"mean\"]:\n",
    "                        minimal_data[j] = data[j]             \n",
    "        minimal_dataset += [(title, minimal_data)]\n",
    "    return [minimal_dataset]\n",
    "\n",
    "plots_with_error_bars(get_minimal_dataset([dataset1, dataset2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
